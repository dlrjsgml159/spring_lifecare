{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 2s 0us/step\n",
      "Epoch 1/4\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.3196 - accuracy: 0.9103 - val_loss: 0.1436 - val_accuracy: 0.9590\n",
      "Epoch 2/4\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.1366 - accuracy: 0.9612 - val_loss: 0.0984 - val_accuracy: 0.9723\n",
      "Epoch 3/4\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0939 - accuracy: 0.9727 - val_loss: 0.0764 - val_accuracy: 0.9790\n",
      "Epoch 4/4\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0742 - accuracy: 0.9783 - val_loss: 0.0764 - val_accuracy: 0.9788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23ccb3a7cc0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the input image so that each pixel value is between 0 to 1.\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Define the model architecture.\n",
    "model = keras.Sequential([\n",
    "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
    "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "# Train the digit classification model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "  train_images,\n",
    "  train_labels,\n",
    "  epochs=4,\n",
    "  validation_split=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test accuracy: 0.9693999886512756\n",
      "Saved baseline model to: C:\\Users\\han\\AppData\\Local\\Temp\\tmpp7c8pffm.h5\n"
     ]
    }
   ],
   "source": [
    "_, baseline_model_accuracy = model.evaluate(\n",
    "    test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "\n",
    "_, keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model, keras_file, include_optimizer=False)\n",
    "print('Saved baseline model to:', keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.keras.engine.sequential.Sequential'>\n"
     ]
    }
   ],
   "source": [
    "print(type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\han\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_model_optimization\\python\\core\\sparsity\\keras\\pruning_wrapper.py:220: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "prune_low_magnitude_reshape  (None, 28, 28, 1)         1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_conv2d ( (None, 26, 26, 12)        230       \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_max_pool (None, 13, 13, 12)        1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_flatten  (None, 2028)              1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense (P (None, 10)                40572     \n",
      "=================================================================\n",
      "Total params: 40,805\n",
      "Trainable params: 20,410\n",
      "Non-trainable params: 20,395\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# Compute end step to finish pruning after 2 epochs.\n",
    "batch_size = 128\n",
    "epochs = 2\n",
    "validation_split = 0.1 # 10% of training set will be used for validation set. \n",
    "\n",
    "num_images = train_images.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "# Define model for pruning.\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "\n",
    "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "model_for_pruning.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "  1/422 [..............................] - ETA: 0s - loss: 0.1733 - accuracy: 0.9375WARNING:tensorflow:From C:\\Anaconda3\\envs\\tensorflow3.6.5\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "  2/422 [..............................] - ETA: 31s - loss: 0.2001 - accuracy: 0.9375WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0124s vs `on_train_batch_end` time: 0.1316s). Check your callbacks.\n",
      "422/422 [==============================] - 5s 13ms/step - loss: 0.1147 - accuracy: 0.9701 - val_loss: 0.1420 - val_accuracy: 0.9707\n",
      "Epoch 2/2\n",
      "422/422 [==============================] - 5s 12ms/step - loss: 0.1205 - accuracy: 0.9692 - val_loss: 0.0953 - val_accuracy: 0.9745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23cce093fd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logdir = tempfile.mkdtemp()\n",
    "\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "]\n",
    "  \n",
    "model_for_pruning.fit(train_images, train_labels,\n",
    "                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
    "                  callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test accuracy: 0.9751999974250793\n",
      "Pruned test accuracy: 0.9693999886512756\n"
     ]
    }
   ],
   "source": [
    "_, model_for_pruning_accuracy = model_for_pruning.evaluate(\n",
    "   test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy) \n",
    "print('Pruned test accuracy:', model_for_pruning_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 3221226505).\n",
       "Contents of stderr:\n",
       "Warning! ***HDF5 library version mismatched error***\n",
       "The HDF5 header files used to compile this application do not match\n",
       "the version used by the HDF5 library to which this application is linked.\n",
       "Data corruption or segmentation faults may occur if the application continues.\n",
       "This can happen when an application was compiled by one version of HDF5 but\n",
       "linked with a different version of static or shared HDF5 library.\n",
       "You should recompile the application or check your shared library related\n",
       "settings such as 'LD_LIBRARY_PATH'.\n",
       "You can, at your own risk, disable this warning by setting the environment\n",
       "variable 'HDF5_DISABLE_VERSION_CHECK' to a value of '1'.\n",
       "Setting it to 2 or higher will suppress the warning messages totally.\n",
       "Headers are 1.10.4, library is 1.10.5\n",
       "        SUMMARY OF THE HDF5 CONFIGURATION\n",
       "        =================================\n",
       "\n",
       "General Information:\n",
       "-------------------\n",
       "                   HDF5 Version: 1.10.5\n",
       "                  Configured on: 2019-03-04\n",
       "                  Configured by: Visual Studio 14 2015 Win64\n",
       "                    Host system: Windows-10.0.17763\n",
       "              Uname information: Windows\n",
       "                       Byte sex: little-endian\n",
       "             Installation point: C:/Program Files/HDF5\n",
       "\n",
       "Compiling Options:\n",
       "------------------\n",
       "                     Build Mode: \n",
       "              Debugging Symbols: \n",
       "                        Asserts: \n",
       "                      Profiling: \n",
       "             Optimization Level: \n",
       "\n",
       "Linking Options:\n",
       "----------------\n",
       "                      Libraries: \n",
       "  Statically Linked Executables: OFF\n",
       "                        LDFLAGS: /machine:x64\n",
       "                     H5_LDFLAGS: \n",
       "                     AM_LDFLAGS: \n",
       "                Extra libraries: \n",
       "                       Archiver: \n",
       "                         Ranlib: \n",
       "\n",
       "Languages:\n",
       "----------\n",
       "                              C: yes\n",
       "                     C Compiler: C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/x86_amd64/cl.exe 19.0.24218.1\n",
       "                       CPPFLAGS: \n",
       "                    H5_CPPFLAGS: \n",
       "                    AM_CPPFLAGS: \n",
       "                         CFLAGS:  /DWIN32 /D_WINDOWS /W3\n",
       "                      H5_CFLAGS: \n",
       "                      AM_CFLAGS: \n",
       "               Shared C Library: YES\n",
       "               Static C Library: YES\n",
       "\n",
       "                        Fortran: OFF\n",
       "               Fortran Compiler:  \n",
       "                  Fortran Flags: \n",
       "               H5 Fortran Flags: \n",
       "               AM Fortran Flags: \n",
       "         Shared Fortran Library: YES\n",
       "         Static Fortran Library: YES\n",
       "\n",
       "                            C++: ON\n",
       "                   C++ Compiler: C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/x86_amd64/cl.exe 19.0.24218.1\n",
       "                      C++ Flags: /DWIN32 /D_WINDOWS /W3 /GR /EHsc\n",
       "                   H5 C++ Flags: \n",
       "                   AM C++ Flags: \n",
       "             Shared C++ Library: YES\n",
       "             Static C++ Library: YES\n",
       "\n",
       "                            JAVA: OFF\n",
       "                   JAVA Compiler:  \n",
       "\n",
       "Features:\n",
       "---------\n",
       "                   Parallel HDF5: OFF\n",
       "Parallel Filtered Dataset Writes: \n",
       "              Large Parallel I/O: \n",
       "              High-level library: ON\n",
       "                    Threadsafety: OFF\n",
       "             Default API mapping: v110\n",
       "  With deprecated public symbols: ON\n",
       "          I/O filters (external):  DEFLATE DECODE ENCODE\n",
       "                             MPE: \n",
       "                      Direct VFD: \n",
       "                         dmalloc: \n",
       "  Packages w/ extra debug output: \n",
       "                     API Tracing: OFF\n",
       "            Using memory checker: OFF\n",
       " Memory allocation sanity checks: OFF\n",
       "          Function Stack Tracing: OFF\n",
       "       Strict File Format Checks: OFF\n",
       "    Optimization Instrumentation: \n",
       "Bye..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir={logdir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pruned Keras model to: C:\\Users\\han\\AppData\\Local\\Temp\\tmp2z6my8gd.h5\n"
     ]
    }
   ],
   "source": [
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "\n",
    "_, pruned_keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
    "print('Saved pruned Keras model to:', pruned_keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda3\\envs\\tensorflow3.6.5\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\envs\\tensorflow3.6.5\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\han\\AppData\\Local\\Temp\\tmplgzlnrm4\\assets\n",
      "Saved pruned TFLite model to: C:\\Users\\han\\AppData\\Local\\Temp\\tmp7t2bssid.tflite\n"
     ]
    }
   ],
   "source": [
    "#그런 다음 TFLite 용 압축 가능한 모델을 만듭니다.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "pruned_tflite_model = converter.convert()\n",
    "\n",
    "_, pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(pruned_tflite_file, 'wb') as f:\n",
    "  f.write(pruned_tflite_model)\n",
    "\n",
    "print('Saved pruned TFLite model to:', pruned_tflite_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gzipped_model_size(file):\n",
    "  # Returns size of gzipped model, in bytes.\n",
    "  import os\n",
    "  import zipfile\n",
    "\n",
    "  _, zipped_file = tempfile.mkstemp('.zip')\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(file)\n",
    "\n",
    "  return os.path.getsize(zipped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of gzipped baseline Keras model: 78115.00 bytes\n",
      "Size of gzipped pruned Keras model: 25794.00 bytes\n",
      "Size of gzipped pruned TFlite model: 24857.00 bytes\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(pruned_keras_file)))\n",
    "print(\"Size of gzipped pruned TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\han\\AppData\\Local\\Temp\\tmplwo0r00l\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\han\\AppData\\Local\\Temp\\tmplwo0r00l\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved quantized and pruned TFLite model to: C:\\Users\\han\\AppData\\Local\\Temp\\tmp46re21_2.tflite\n",
      "Size of gzipped baseline Keras model: 78115.00 bytes\n",
      "Size of gzipped pruned and quantized TFlite model: 7868.00 bytes\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_and_pruned_tflite_model = converter.convert()\n",
    "\n",
    "_, quantized_and_pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(quantized_and_pruned_tflite_file, 'wb') as f:\n",
    "  f.write(quantized_and_pruned_tflite_model)\n",
    "\n",
    "print('Saved quantized and pruned TFLite model to:', quantized_and_pruned_tflite_file)\n",
    "\n",
    "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "print(\"Size of gzipped pruned and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(quantized_and_pruned_tflite_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def evaluate_model(interpreter):\n",
    "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "  # Run predictions on ever y image in the \"test\" dataset.\n",
    "  prediction_digits = []\n",
    "  for i, test_image in enumerate(test_images):\n",
    "    if i % 1000 == 0:\n",
    "      print('Evaluated on {n} results so far.'.format(n=i))\n",
    "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "    # the model's input data format.\n",
    "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
    "    interpreter.set_tensor(input_index, test_image)\n",
    "\n",
    "    # Run inference.\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Post-processing: remove batch dimension and find the digit with highest\n",
    "    # probability.\n",
    "    output = interpreter.tensor(output_index)\n",
    "    digit = np.argmax(output()[0])\n",
    "    prediction_digits.append(digit)\n",
    "\n",
    "  print('\\n')\n",
    "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "  prediction_digits = np.array(prediction_digits)\n",
    "  accuracy = (prediction_digits == test_labels).mean()\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated on 0 results so far.\n",
      "Evaluated on 1000 results so far.\n",
      "Evaluated on 2000 results so far.\n",
      "Evaluated on 3000 results so far.\n",
      "Evaluated on 4000 results so far.\n",
      "Evaluated on 5000 results so far.\n",
      "Evaluated on 6000 results so far.\n",
      "Evaluated on 7000 results so far.\n",
      "Evaluated on 8000 results so far.\n",
      "Evaluated on 9000 results so far.\n",
      "\n",
      "\n",
      "Pruned and quantized TFLite test_accuracy: 0.9693\n",
      "Pruned TF test accuracy: 0.9693999886512756\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=quantized_and_pruned_tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "test_accuracy = evaluate_model(interpreter)\n",
    "\n",
    "print('Pruned and quantized TFLite test_accuracy:', test_accuracy)\n",
    "print('Pruned TF test accuracy:', model_for_pruning_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow3.6.5",
   "language": "python",
   "name": "tensorflow3.6.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
